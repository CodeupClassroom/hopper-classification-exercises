{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c8883a2",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "\n",
    "Plan - Acquire - **Prepare** - Explore - Model - Deliver\n",
    "\n",
    "**Goal**: Prepare, tidy, and clean the data so that it is ready for exploration and analysis.\n",
    "\n",
    "**Input:** 1 or more dataframes acquired through the \"acquire\" step.\n",
    "\n",
    "**Output:** 1 dataset split into 3 samples in the form of dataframes: train, validate & test.\n",
    "\n",
    "**Artifact:** `prepare.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import splitting and imputing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# turn off pink boxes for demo\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import our own acquire module\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd05956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cae3fc",
   "metadata": {},
   "source": [
    "# STEP 1: Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows & columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc579da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about the dataframe: column names, rows, datatypes, non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics for numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out distributions of numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .describe with object columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for fare using .value_counts.\n",
    "# Using sort = false will sort by bin values as opposed to the frequency counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b71d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with missing values and the total of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06662f7",
   "metadata": {},
   "source": [
    "# STEP 2: Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e3d75f",
   "metadata": {},
   "source": [
    "#### Duplicate Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates...run just in case; reassign and check the shape of my data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b52a9",
   "metadata": {},
   "source": [
    "#### Missing Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9612cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with too many missing values for now and reassign; check the shape of my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e881c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that the columns are dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d4299",
   "metadata": {},
   "source": [
    "We could fill `embark_town` with most common value, 'Southampton', by hard-coding the value using the `fillna()` function, as below. Or we could use an imputer. We will demonstrate the imputer after the train-validate-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99e12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run .fillna() on the entire df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that missing values in embark_town have been handled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9be30",
   "metadata": {},
   "source": [
    "#### Outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63d6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf998eae",
   "metadata": {},
   "source": [
    "#### Erroneous Values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f56246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5cf6a6",
   "metadata": {},
   "source": [
    "#### Correct Datatypes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e2218a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46a1b4c2",
   "metadata": {},
   "source": [
    "#### Text Normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15829cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16813829",
   "metadata": {},
   "source": [
    "#### Tidy Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each column should only represent one variable\n",
    "# Each row should be one observation (passenger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b720c45",
   "metadata": {},
   "source": [
    "#### Create New Variables?\n",
    "\n",
    "Get dummy vars for sex and embark_town\n",
    "\n",
    "dummy_na: create a dummy var for na values, also?\n",
    "drop_first: drop first dummy var (since we know if they do not belong to any of the vars listed, then they must belong to the first one that is not listed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c3e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb828829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dummy_df dataframe above with the original df and validate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eaf5fb",
   "metadata": {},
   "source": [
    "#### Rename Columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590913b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0fd214e",
   "metadata": {},
   "source": [
    "#### Scaling Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You want to scale data when you're using methods based on measures\n",
    "# of how far apart data points, like support vector machines\n",
    "# or k-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c092f",
   "metadata": {},
   "source": [
    "### Lets not do that all over again repeatedly...lets make a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40039af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae4b38ce",
   "metadata": {},
   "source": [
    "Testing that the function does what we intend for it to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f44a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf2c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac92a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e577cd8",
   "metadata": {},
   "source": [
    "# Step 3: Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% test, 80% train_validate\n",
    "# then of the 80% train_validate: 30% validate, 70% train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d445c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb53c31f",
   "metadata": {},
   "source": [
    "### Turn it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ae439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d30f94b1",
   "metadata": {},
   "source": [
    "Testing that the function is doing what we intend for it to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c44d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f1ae7eb",
   "metadata": {},
   "source": [
    "# Alternative Method: Impute\n",
    "\n",
    "We can impute values using the mean, median, mode (most frequent), or a constant value. We will use sklearn.imputer.SimpleImputer to do this.\n",
    "\n",
    "1. Create the imputer object, selecting the strategy used to impute (mean, median or mode (strategy = 'most_frequent').\n",
    "1. Fit to train. This means compute the mean, median, or most_frequent (i.e. mode) for each of the columns that will be imputed. Store that value in the imputer object.\n",
    "1. Transform train: fill missing values in train dataset with the stored value\n",
    "1. Transform validate: fill missing values in validate dataset with the stored value\n",
    "1. Transform test: fill missing values in test dataset with the stored value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fresh Titanic data to use with missing values in embark_town again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eadf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY look at train dataset after we split our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb6f5c",
   "metadata": {},
   "source": [
    "Create the `SimpleImputer` object, which we will store in the variable `imputer`. In the creation of the object, we will specify the strategy to use (mean, median, most_frequent). Essentially, this is creating the instructions and assigning them to a variable, `imputer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5514a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "119fab39",
   "metadata": {},
   "source": [
    "`Fit` the imputer to the columns in the training df. This means that the imputer will determine the most_frequent value, or other value depending on the strategy called, for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c49c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "278a0d8e",
   "metadata": {},
   "source": [
    "It will store that value in the imputer object to use upon calling `transform`. We will call `transform` on our train, validate, and test datasets to fill any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b6bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that there are no longer any Null values in embark_town."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30fc668",
   "metadata": {},
   "source": [
    "### Simplify our life with a function\n",
    "\n",
    "Note: the `clean_data()` function is already dealing with missing values. If we want to use imputation, we will need to go back and tweak our earlier function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yay functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c6368",
   "metadata": {},
   "source": [
    "### We can create a function made of our other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6687d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another function? YES PLZ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbf4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire fresh Titanic data to test my funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996da379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run final prepare function and validate what that the function is working properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80efa6",
   "metadata": {},
   "source": [
    "# Exercise Time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
